----------------------
PART ONE: EXPLAINATION
----------------------
1. tr -c 'A-Za-z' '[\n*]'
   -c 'A-Za-z': complement of letters
   * Finds non-letters
   * Replace each of them with new line char

2. tr -cs 'A-Za-z' '[\n*]'
   -s: squeeze repeating sequences
   * Find non-letters
   * Remove repeating ones
   * Replace with new line char
   
tr -cs 'A-Za-z' '[\n*]' | sort
   * Find non-letters
   * Remove repeating ones
   * Replace with new line char
   * Sort them
   
tr -cs 'A-Za-z' '[\n*]' | sort -u
   * Find non-letters
   * Remove repeating ones
   * Replace with new line char
   * Sort them
   * Output only the unique ones
   
tr -cs 'A-Za-z' '[\n*]' | sort -u | comm - words
   * Find non-letters
   * Remove repeating ones
   * Replace with new line char
   * Sort them
   * Output only the unique ones
   * Compare the output with the file words
   
tr -cs 'A-Za-z' '[\n*]' | sort -u | comm -23 - words
   - comm -2: Suppress lines unique in words
   - comm -3: Suppress lines appears in both files
   * Find non-letters
   * Remove repeating ones
   * Replace with new line char
   * Sort them
   * Output only the unique ones
   * Compare the output with the file words
   * Output lines apprearing only in the HTML


----------------------
PART TWO: BUILDWORDS
----------------------

#!/bin/bash

#extract only the words between <td> and </td> 
grep -Po '<td>\K.*(?=</td>)' |

#save the even lines(Hawaiian) to dic.txt
sed '1d; n; d' |

#remove <?>s within the words
sed 's/<\/\?.>//g' |

#to lower
tr '[:upper:]' '[:lower:]' |

#replace ` with '
sed 's/`/'\''/g' |

#seperate words containing ' ' or ', '
sed 's/,\? /\n/g' |

#delete non-hawaiian words
sed '/[^(pk'\''mnwlhaeiou)]/d' |

#sort
sort -u

-------------------------
PART THRRE: SPELL CHECKER
-------------------------

# English checker on web #
--------------------------
cat assign2.html |
tr '[:upper:]' '[:lower:]' |
tr -cs 'A-Za-z' '[\n*]' |
sort -u |
comm -23 - words2 >en2web #save for later

#count
cat en2en |
wc -l

The output is: 39


# Hawaiian checker on web #
--------------------------
cat assign2.html |
tr '[:upper:]' '[:lower:]' |
tr -cs '[A-Za-z]' '[\n*]' | # remove non-letters
sed '/[^(pk'\''mnwlhaeiou)]/d' | # remove non-hawaiians
sort -u |
comm -23 - hwords >hw2web #save for later

#count
cat hw2web|
wc -l

The output is: 37


#hawaiian checker on hwords#
--------------------------
cat hwords |
tr -cs '[A-Za-z]' '[\n*]'| # remove non-letters
sed '/[^(pk'\''mnwlhaeiou)]/d' | # remove non-hawaiians
sort -u |
comm -23 - hwords |
wc -l

The output is: 0


# misspeclled as English but not as Hawaiian #
----------------------------------------------
#first,get rid of non-hawaiian words in en2web
#then compare it with hwords


cat en2web |
sed '/[^(pk'\''mnwlhaeiou)]/d' | # remove non-hawaiian
comm -12 - hwords

The output is:
halau
lau
wiki


# misspeclled as Hawaiian but not as English #
--------------------------------------------
#contained in hw2web but not in words

comm -12 hw2web words

The output includes:
...
people
paul
mail
like
line
link
...